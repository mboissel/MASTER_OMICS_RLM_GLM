---
title: "TP R√©gression lin√©aire multiple et Mod√®le Lin√©aire G√©n√©ralis√©"
author: "Mathilde Boissel"
date: "25/01/2021"
output: word_document
toc: true 
toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
```

```{r logo-udl, results="asis", echo = FALSE, fig.align='center'}
knitr::include_graphics("./Images_includ/logo_univ-lille-large.png") 
```

\newpage 

# R√©gression lin√©aire multiple

## Exercice 1 : lecture des sorties

Nous allons utiliser le jeu de donn√©es `trees`, disponible dans le package `datasets` (nativement charg√© dans R).  

On souhaite expliquer la variable quantitative Volume (Volume of timber in cubic ft) √† partir de 2 autres variables quantitatives Girth (Tree diameter (rather than girth, actually) in inches) et Height (Height in ft).  

Pour se faire on consid√®re le mod√®le rlm suivant : 

$$Volume = \beta_0 + \beta_1 \times Girth + \beta_2 \times Height +\varepsilon$$

o√π $\varepsilon \sim \mathcal{N}(0, \sigma^2)$, les param√®tres $\beta_0, \beta_1, \beta_2$ et $\sigma$ sont des r√©els inconnus. On les estime alors avec $n$ observations de $(Volume, Girth, Height)$ par la meth√®de des mco. Un r√©sum√© et une visualisation des donn√©es est propos√© ci-dessous : 

```{r exo1, eval = TRUE, echo = TRUE}
# head(datasets::trees)
pairs(trees)
str(trees)
```

Puis le tableau de ce mod√®le rlm renvoy√© par la commande `summary` est affich√© ci-dessous : 

```{r exo1_reg, eval = TRUE, echo = TRUE}
reg <- lm(formula = Volume ~ Girth + Height, data = trees)
summary(reg)
``` 

1/ Quelle est la valeur de $n$ ? 
<!-- n=31, info vu dans le str, ou d√©ductible avec les d.d.l. -->

2/ Donner l'emco ponctuel de $\beta_2$. 
<!-- beta_2 concerne Height = 0.3393 -->

3/ Est ce que la r√©gression est hautement significative pour `Girth` ? 
<!-- hautement significatif oui car p-valeur <0.001, symbolis√© par *** -->

4/ Donner un intervalle de confiance pour $\beta_2$ √† 95%.

```{r confint, echo = FALSE, eval = FALSE}
confint(reg, level = 0.95)
# ou plus pr√©cisement uniquement : 
confint(reg, level = 0.95)[3, ]
```

5/ Donner le R2 et le R2 ajust√©. 
<!-- Multiple R-squared:  0.948,	Adjusted R-squared:  0.9442  -->

6/ Donner $f_{obs}$ et la p-valeur du test global de Fisher. Quelle est l‚Äôhypoth√®se nulle associ√©e √† ce test statistique ?
<!-- F-statistic:   255 et sa p-value: < 2.2e-16 -->
<!-- H0 : tous les beta = ùüé contre H1 : ‚Äúil existe au moins un coefficient non nul‚Äù. -->
<!-- ici on rejette H0, cela signifie que le modele est pertinent  -->

7-A/ Donner la pr√©diction de Volume pour Girth valant 8.3 et Height valant 70 (avec la commande R et calcul√© "manuellement")

```{r predictA, echo = FALSE, eval = FALSE}
## avec R : 
predict(reg, data.frame(Girth = 8.3, Height = 70))
# predict(reg)[1] ## On remarque que c'est justement la premi√®re observation du jeu de donn√©es, et predict se base par defaut sur le jeu de donn√©es utilis√© pour la R√©gression. 

## Manuellement : prediction de y_x = b0 * 1 + b1 * Girth + b2 * Height
sum(reg$coefficients * c(const = 1, Girth = 8.3, Height = 70))
```

7-B/ Donner un intervalle de confiance √† cette pr√©diction. 

```{r predictB, echo = FALSE, eval = FALSE}
predict(reg, data.frame(Girth = 8.3, Height = 70), interval = "confidence")
```

8/ Repr√©senter le(s) graphique(s) des r√©sidus. Est-ce que les hypoth√®ses standards semblent √™tre satisfaites ?

```{r residus, echo = FALSE, eval = FALSE}
e = residuals(reg)
plot(e)
abline(h = 0, col = "red")
## ou directement : 
par(mfrow = c(2, 2))
plot(reg)
## pour aller plus loin sur l'indendances des erreurs : 
par(mfrow = c(1, 2))
acf(e)
pacf(e)

par(mfrow = c(1, 1))
```

9/ √âtude de la multicolin√©arit√© : **R√®gle de Klein**

Pour chaque variable d'un rlm, 2 √† 2, Si une ou plusieurs corr√©lations au carr√© sont proches du R2 du mod√®le, alors on soup√ßonne que les variables associ√©es sont colin√©aires.  

Calculer le carr√© du coefficient de corr√©lation entre Girth et Height.  
Ces variables sont-elles colin√©aires ? 

```{r multicor, echo = FALSE, eval = FALSE}
cor(trees$Girth, trees$Height)^2
```

<!-- Cela renvoie 0.26, lequel est √©loign√© de R2 = 0.948.   -->
<!-- Donc, par la r√®gle de Klein, il n‚Äôy a pas de lien lin√©aire entre Girth et Height.  -->

10/ Y-a-t'il des valeurs aberrantes/extr√™mes dans notre jeu de donn√©es ? 

10-A/ Afin de d√©tecter la pr√©sence de valeurs aberrantes, on peut utiliser une mesure nomm√©e **Distance de Cook**. 
On envisage l'anormalit√© de la i-√©me observation si $d_i>1$.  

Mais attention retirer strictement des valeurs sur ce seul crit√®re serait une d√©cision un peu rapide. M√™me "extr√™mes", si les valeurs sont "vraiment" observ√©es (mais ne nous arrangent pas), nous ne pouvons pas gommer un point pour am√©liorer le mod√®le. 

Calculer les distances de cooks.  

```{r cook, echo = TRUE, eval = FALSE}
cook <- cooks.distance(reg)
cook[cook>1]
```

<!-- aucune distance > 1, pourtant le graphique des r√©sidus `plot(e)`(plus hait) montrait un point un peu √©loign√© des autres... -->

10-B/ Observations influentes : Pour identifier les observations qui influent le plus dans les estimations (celles dont une faible variation des valeurs induit une modification importante des estimations), plusieurs outils compl√©mentaires existent : les **DFBETAS**, les **DFFITS**, les **rapports de covariance** et les **distances de Cook**. Si besoin est, pour identifier les observations influentes, on fait :

```{r influence, echo = TRUE, eval = FALSE}
summary(influence.measures(reg))
``` 

R√©pondre √† la question initiale. 


\newpage

## Exercice 2 : Comparaison de 2 mod√®les

A notre jeu de donn√©es `trees`, nous ajoutons 2 nouvelles variables cr√©√©es de toute pi√®ce comme suit : 

```{r exo2, eval = TRUE, echo = TRUE}
mydata <- trees
mydata$X3 <- rnorm(n = nrow(trees), mean = 30, sd = 1)
mydata$X4 <- rnorm(n = nrow(trees), mean = 60, sd = 3)
str(mydata)
```

Pour tester l'influence d'une ou plusieurs variables dans un mod√®le, tout en prenant en consid√©ration les autres variables, on peut utiliser le **test ANOVA** : si p-valeur > 0.05, alors les variables √©tudi√©es ne contribuent pas significativement au mod√®le.

Ici, on veut tester H0 : $\beta_3 = \beta_4 = 0$ en sachant qu'il y a toujours les variables Girth et Height dans le mod√®le. On effectue :

```{r anova, echo = TRUE, eval = TRUE}
reg1 = lm(Volume ~ Girth + Height + X3 + X4, data = mydata)
reg2 = lm(Volume ~ Girth + Height, data = mydata)
anova(reg1, reg2)
```

1/ A la lecture de ces r√©sultats, que pouvez-vous conclure ? 

<!-- On lit la p-valeur = 0.5028 -->
<!-- si p-valeur > 0.05, alors les variables √©tudi√©es ne contribuent pas significativement au mod√®le. -->
<!-- ici le meilleur mod√®le est le modele 2 : X3 et X4 ne contribuent pas significativement au mod√®le... (comme attendu!)-->

2/ Crit√®res **AIC** et **BIC**

Ces crit√®res AIC et BIC reposent sur un compromis "biais - parcimonie". Plus petits ils sont, meilleur est le mod√®le.

```{r AICBIC, echo = TRUE, eval=TRUE}
message("reg1")
message("AIC = ", AIC(reg1))
message("BIC = ", BIC(reg1))

message("reg2")
message("AIC = ", AIC(reg2))
message("BIC = ", BIC(reg2))
```

Votre conclusion change-t-elle avec ces nouveaux r√©sultats ? 
<!-- Non, le mod√®le 2 a toujours les plus petites valeurs. -->

\newpage

# GLM : R√©gression logistique

On consid√®re une population P divis√©e en 2 groupes d‚Äôindividus G1 et G2 distinguables par des variables $X_1,..., X_p$. Soit Y la variable qualitative valant 1 si l‚Äôindividu consid√©r√© appartient √† G1 et 0 sinon. On souhaite expliquer Y √† partir de $X_1,..., X_p$.

Dans le cadre d'un R√©gression logistique, on souhaite estimer la probabilit√© qu‚Äôun individu i v√©rifiant $(X_1,..., X_p) = x$ appartienne au groupe G1 :  

$$p(x) = \mathbb{P}(\{Y=1\}|x) = \mathbb{E}(Y|x)$$
$$p(x) = \beta_0 + \beta_1x_1 + ... + \beta_px_p$$
La transformation logit s'applique donc dans ce cas.  


## Exercice 3 : R√©gression logistique simple


Dans cette configuration, nous utiliserons des donn√©es `T2Ddata`, simul√©es comme suit :  

+ `CC` est la variable binaire qui traduit le statut "cas" (1) pour d√©finir le groupe des enfants diab√©tiques ou "ctrl", controle, (0) pour d√©finir les enfants non diab√©tiques. 
+ `weight` la variable num√©rique qui repr√©sente le poids des individus.  

```{r T2Ddata, echo = TRUE, eval = TRUE}
T2Ddata <- data.frame(
  weight = c(35.9, 38.3, 55.7, 41.7, 43.2, 49.1, 45, 45.3, 46.1, 46.9, 48.1, 
    48.9, 49.2, 51.2, 56.4, 51.7, 51.8, 52.6, 52.9, 51.3, 53.7, 55, 
    55.4, 55.8, 58, 58.7, 60.3, 61.1, 61.5, 63.1), 
  CC = factor(x = c(rep("0", 15), rep("1", 15)), levels = c("0", "1"), labels = c("CTRL", "CAS")) 
)
str(T2Ddata)
```

1/ Visualiser les donn√©es 

```{r viz, echo = FALSE, eval = TRUE}
plot(T2Ddata$weight, T2Ddata$CC)
```

2/ R√©aliser la r√©gression logistique mod√©lisant `CC` en fonction de `weight`. 

```{r glmlog, eval = FALSE, echo = FALSE}
reg <- glm(formula = CC ~ weight, data = T2Ddata, family = binomial(link = "logit"))
summary(reg)
```

3/ **Rapport des c√¥tes** ou **odds ratio**  

Si $X_j$ augmente d‚Äôune unit√©, alors le rapport des c√¥tes est $RC_j = \mathbb{exp}(\beta_j)$.   

Par cons√©quent,  

+ si $RC_j$ > 1, l‚Äôaugmentation d‚Äôune unit√© de Xj entra√Æne une augmentation des chances que {Y = 1} se r√©alise,  
+ si $RC_j$ = 1, l‚Äôaugmentation d‚Äôune unit√© de Xj n‚Äôa pas d‚Äôimpact sur Y ,  
+ si $RC_j$ < 1, l‚Äôaugmentation d‚Äôune unit√© de Xj entra√Æne une augmentation des chances que {Y = 0} se r√©alise.

Calculer l'odd ration de weight.  

<!-- Dans R, on obtient ces valeurs comme suit :  -->

```{r OR, eval = FALSE, echo = FALSE}
OR = exp(coef(reg)) 
OR>1
```

<!-- L'OR de weight est > 1 donc l‚Äôaugmentation d‚Äôune unit√© de weight entra√Æne une augmentation des chances que {CC = 1} se r√©alise, i.e. l'augmentation du poids augmente le risque de venir diabetique, selon nos donn√©es.  -->

4/ Avec ce nouveau jeu de donn√©es `T2Ddata2`, refaites les m√™mes op√©ration (question 1 √† 3). Que se passe-t-il ?  

```{r T2Ddata2, echo = TRUE, eval = TRUE}
T2Ddata2 <- data.frame(
  weight = sort(c(35.9, 38.3, 55.7, 41.7, 43.2, 49.1, 45, 45.3, 46.1, 46.9, 48.1, 
    48.9, 49.2, 51.2, 56.4, 51.7, 51.8, 52.6, 52.9, 51.3, 53.7, 55, 55.4, 55.8, 58, 58.7, 60.3, 61.1, 61.5, 63.1)), 
  CC = factor(x = c(rep("0", 15), rep("1", 15)), levels = c("0", "1"), labels = c("CTRL", "CAS")) 
)
str(T2Ddata2)
```

<!-- Executer les commandes suivantes  -->

```{r glmlog2, eval = FALSE, echo = FALSE}
plot(T2Ddata2$weight, T2Ddata2$CC)
reg2 <- glm(formula = CC ~ weight, data = T2Ddata2, family = binomial(link = "logit"))
summary(reg2)
OR2 = exp(coef(reg2))
OR2
```

<!-- Le graphique nous montre une tr√®s nette partition entre les mesures -->
<!-- A la r√©alisation du GLM : Le warning suivant s'affiche :  -->
<!-- Warning messages: -->
<!-- 1: glm.fit: l'algorithme n'a pas converg√©  -->
<!-- 2: glm.fit: des probabilit√©s ont √©t√© ajust√©es num√©riquement √† 0 ou 1  -->
<!-- L'OR de weight "explose" -->

<!-- Ici la mod√©lisation n'√©tait pas pertinente car la partition entre les 2 groupes √©tait total selon la mesure utilis√©e dans le mod√®le. On s'en rend un peu mieux compte avec le boxplot suivant : `boxplot(T2Ddata2$weight~T2Ddata2$CC)` -->

\newpage

## Exercice 4 : R√©gression logistique multiple

Nous allons utiliser le jeu de donn√©es `esoph`, disponible dans le package `datasets` (nativement charg√© dans R).  

Soit $j \in \{0,..., p\}$. Le **test de la d√©viance** vise √† √©valuer l‚Äôinfluence (ou la contribution) de Xj sur Y. La p-valeur associ√©e utilise la loi du Chi-deux : si \*, l‚Äôinfluence de Xj sur Y est significative, si \*\*, elle est tr√®s significative et si \*\*\*, elle est hautement significative.  

Ici, on souhaite mod√©liser la proportion d'individus cas/control d√©finit dans les 2 colonnes ncases et ncontrols.  

Evaluer les 2 mod√®les suivants et noter les diff√©rences. 

```{r esoph, echo = TRUE, eval = FALSE}
str(esoph)

model1 <- glm(
  cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp,
  data = esoph, family = binomial(link = "logit")
)
summary(model1)
anova(model1, test = "Chisq")

model2 <- glm(
  cbind(ncases, ncontrols) ~ agegp + unclass(tobgp) + unclass(alcgp),
  data = esoph, family = binomial()
)
summary(model2)
anova(model2, test = "Chisq")
```

<!-- Modele 1 effets avec interaction de alcohol et tobacco + groupe d'age  -->
<!-- Modele 2 test un effet lin√©aire de alcohol et tobacco (avec unclass) et sans interaction. -->


\newpage

# Pour aller plus loin

## Comple√©ent

Les √©l√©ments ci-dessous ne seront pas forcement test√©s en TP (ni vu en cours).  
Mais vous pourrez commencer √† vous familiariser avec ces concepts gr√¢ces √† ces quelques remarques.  
De plus si vous voulez aller plus loin, je vous recommande de r√©aliser les √©tudes propos√© ici :  

https://chesneau.users.lmno.cnrs.fr/etudes-reg.pdf

Le cours allant avec est aussi disponible ici :  

https://chesneau.users.lmno.cnrs.fr/Reg-M2.pdf

## Multicolin√©arit√©

la variance de $\hat{\beta}_j$ explose et entra√©ne une grande instabilit√© dans l'estimation de $\beta_j$ et fausse tous les tests statistiques.  

En particulier, si au moins une variable parmi $X_1, ..., X_p$ a une liaison lin√©aire avec d'autres, il est possible qu'aucune variable ne montre d'influence significative sur Y et cela, en d√©pit de toute logique, et du test de Fisher qui peut quand m√™me indiquer une influence significative globale des coefficients (car il prend en compte toutes les variables).  

### R√©√®le de Klein

Si une ou plusieurs valeurs au carr√© sont proches de R2, alors on soup√ßonne que les variables associ√©es sont colin√©aires. 

```{r, klein, echo = TRUE, eval = FALSE}
c = cor(cbind(X1, X2, X3), cbind(X1, X2, X3))
c^2
``` 

### VIF

On appelle **vif** $V_j$ le facteur d'inflation de la variance associ√© √† la variable $X_j$. Si $V_j \ge 5$, alors on admet que $X_j$ a un lien lin√©aire avec les autres variables. 

```{r, vif, echo = TRUE, eval = FALSE}
library(car)
vif(reg)
``` 

## S√©lection de variables

Il est int√©ressant de d√©terminer la meilleure combinaison des variables X1, ..., Xp qui explique Y.  r l‚Äôapproche qui consiste √† √©liminer d‚Äôun seul coup les variables non significatives n‚Äôest pas bonne ;  ertaines variables peuvent √™tre corr√©l√©es √† d‚Äôautres, ce qui peut masquer leur r√©elle influence sur Y.

Plusieurs approches sont possibles :

+ Approche exhaustive,
+ Approche en arri√®re,
+ Approche en avant,
+ Approche pas √† pas. 

Rappel sur les crit√®res Cp, AIC et BIC :  
Ces crit√®res Cp de Mallows, AIC et BIC reposent sur un compromis "biais - parcimonie". Plus petits ils sont, meilleur est le mod√®le.

```{r selection, echo = TRUE, eval = FALSE}
AIC(reg)
BIC(reg)

library(leaps)
v = regsubsets(Y ~ X1 + X2 + X3, w, method = "backward")
plot(v, scale = "bic")
# Notons que l'option scale = "aic" n'existe pas. On obtiendrait toutefois la m√©me s√©lection
# de variables que celle obtenue avec l'option scale = "bic"

library(stats)
# Pour utiliser l'approche pas √† pas avec le AIC, puis obtenir les r√©sultats statistiques associ√©s au mod√®le s√©lectionn√© :
reg2 = step(reg, direction = "both", k = 2)
summary(reg2)
# Pour consid√©rer le BIC, on prend k = log(length(Y))
``` 


