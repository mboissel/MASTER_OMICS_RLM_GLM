---
title: "TP R√©gression lin√©aire multiple et Mod√®le Lin√©aire G√©n√©ralis√©"
author: "Mathilde Boissel"
date: "25/01/2021"
output: word_document
toc: true 
toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
```

```{r logo-udl, results="asis", echo = FALSE, fig.align='center'}
knitr::include_graphics("./Images_includ/logo_univ-lille-large.png") 
```

\newpage 

# R√©gression Lin√©aire Multiple (rlm)

## Exercice 1 : lecture des sorties

Nous allons utiliser le jeu de donn√©es `trees`, disponible dans le package `datasets` (nativement charg√© dans R).  

On souhaite expliquer la variable quantitative Volume (Volume of timber in cubic ft) √† partir de 2 autres variables quantitatives Girth (Tree diameter (rather than girth, actually) in inches) et Height (Height in ft).  

Pour se faire on consid√®re le mod√®le rlm suivant : 

$$Volume = \beta_0 + \beta_1 \times Girth + \beta_2 \times Height +\varepsilon$$

o√π $\varepsilon \sim \mathcal{N}(0, \sigma^2)$, les param√®tres $\beta_0, \beta_1, \beta_2$ et $\sigma$ sont des r√©els inconnus. On les estime alors avec $n$ observations de $(Volume, Girth, Height)$ par la m√©thode des mco (moindres carr√©es ordinaires). 

=> Ex√©cuter les commandes et r√©pondre aux questions. 

Un r√©sum√© et une visualisation des donn√©es est propos√© ci-dessous : 

```{r exo1, eval = TRUE, echo = TRUE}
# head(datasets::trees)
pairs(trees)
str(trees)
```

Puis le tableau de ce mod√®le rlm renvoy√© par la commande `summary` est affich√© ci-dessous : 

```{r exo1_reg, eval = TRUE, echo = TRUE}
reg <- lm(formula = Volume ~ Girth + Height, data = trees)
summary(reg)
``` 

1/ Quelle est la valeur de $n$ ? 
<!-- n=31, info vu dans le str, ou d√©ductible avec les d.d.l. -->
<!-- `nrow(trees)` donne aussi le nombre de ligne dans un dataset -->

2/ Donner l'emco ponctuel de $\beta_2$. 
<!-- beta_2 concerne Height = 0.3393 -->
<!-- `coef(reg)` retourne les coefficents, coef(reg)[3] donnera directement Beta2 -->
<!-- ou  `res <- summary(reg)` et faire `res$coefficients` -->

3/ Est-ce que la r√©gression est hautement significative pour `Girth` ? 
<!-- A lire dans le sortie du summary(reg) -->
<!-- hautement significatif oui car p-valeur <0.001, symbolis√© par *** -->

4/ Donner un intervalle de confiance pour $\beta_2$ √† 95%.

```{r confint, echo = FALSE, eval = FALSE}
confint(reg, level = 0.95)
# ou plus pr√©cisement uniquement : 
confint(reg, level = 0.95)[3, ]
```

5/ Donner le R2 et le R2 ajust√©. 
<!-- a lire avec `summary(reg)` -->
<!-- Multiple R-squared:  0.948,	Adjusted R-squared:  0.9442  -->
<!-- On peut aussi les obtenir comme suit :  -->
<!-- res <- summary(reg) -->
<!-- `res$r.squared` et `res$adj.r.squared` -->

6/ Donner $f_{obs}$ et la p-valeur du test global de Fisher. Quelle est l‚Äôhypoth√®se nulle associ√©e √† ce test statistique ?
<!-- a lire avec `summary(reg)`  -->
<!-- F-statistic:   255 et sa p-value: < 2.2e-16 -->
<!-- H0 : tous les beta = ùüé contre H1 : ‚Äúil existe au moins un coefficient non nul‚Äù. -->
<!-- ici on rejette H0, cela signifie que le modele est pertinent -->

<!-- La statistique de Fisher peut aussi se relire ici : `res$fstatistic`,  -->
<!-- Avec la fonction `pf`, on pourrait aller retrouver la p-valeur exact de Fisher : `pf(q = res$fstatistic[["value"]],df1 = res$fstatistic[["numdf"]], df2 = res$fstatistic[["dendf"]], lower.tail=FALSE)` -->


7-A/ Donner la pr√©diction de Volume pour Girth valant 8.3 et Height valant 70 (avec la commande R et calcul√© "manuellement")

```{r predictA, echo = FALSE, eval = FALSE}
## avec R : 
predict(reg, data.frame(Girth = 8.3, Height = 70))
# predict(reg)[1] ## On remarque que c'est justement la premi√®re observation du jeu de donn√©es, et predict se base par defaut sur le jeu de donn√©es utilis√© pour la R√©gression. 

## Manuellement : prediction de y_x = b0 * 1 + b1 * Girth + b2 * Height
sum(reg$coefficients * c(const = 1, Girth = 8.3, Height = 70))
```

7-B/ Donner un intervalle de confiance √† cette pr√©diction. 

```{r predictB, echo = FALSE, eval = FALSE}
predict(reg, data.frame(Girth = 8.3, Height = 70), interval = "confidence")
```

8/ Repr√©senter le(s) graphique(s) des r√©sidus. Est-ce que les hypoth√®ses standards semblent √™tre satisfaites ?

```{r residus, echo = FALSE, eval = FALSE}
e = residuals(reg)
plot(e)
abline(h = 0, col = "red")
## ou directement : 
par(mfrow = c(2, 2))
plot(reg)
## Pour faire un zoom sur le premier graph qui semble avoir des prob√®mes : 
par(mfrow = c(1,1)); plot(reg, 1)
## une structure est bien visible, nous n'avons pas une sym√©trie autour de l'axe y = 0. On pourrait supposer que les r√©sidus sont d√©pendants
# par(mfrow = c(1,1)); plot(reg, 2)

## pour aller plus loin sur l'indendances des erreurs : 
par(mfrow = c(1, 2))
acf(e)
pacf(e)

par(mfrow = c(1, 1)) ## pour remettre les params graphic 
```

9/ √âtude de la multicolin√©arit√© : **R√®gle de Klein**

Pour chaque variable d'un mod√®le de rlm, 2 √† 2, Si une ou plusieurs corr√©lations au carr√© sont proches du R2 du mod√®le, alors on soup√ßonne que les variables associ√©es sont colin√©aires.  

Calculer le carr√© du coefficient de corr√©lation entre Girth et Height.  
Soup√ßonne-t-on ces variables d'√™tre colin√©aires ? 

```{r multicor, echo = FALSE, eval = FALSE}
cor(x = trees$Girth, y = trees$Height)^2
# A comparer avec : summary(reg)$r.squared
```

<!-- Cela renvoie 0.26, lequel est √©loign√© de R2 = 0.948.   -->
<!-- Donc, par la r√®gle de Klein, il n‚Äôy a pas de lien lin√©aire entre Girth et Height.  -->

10/ Y-a-t'il des valeurs aberrantes/extr√™mes dans notre jeu de donn√©es ? 

10-A/ Afin de d√©tecter la pr√©sence de valeurs aberrantes, on peut utiliser une mesure nomm√©e **Distance de Cook**. 
On envisage l'anormalit√© de la i-√©me observation si $d_i>1$.  

Mais attention retirer strictement des valeurs sur ce seul crit√®re serait une d√©cision un peu rapide. M√™me "extr√™mes", si les valeurs sont "vraiment" observ√©es (mais ne nous arrangent pas), nous ne pouvons pas gommer un point pour am√©liorer le mod√®le. 

Calculer les distances de cooks.  

```{r cook, echo = TRUE, eval = FALSE}
cook <- cooks.distance(reg)
cook[cook>1]
```

<!-- aucune distance > 1, pourtant le graphique des r√©sidus `plot(e)`(plus haut) montrait un point un peu √©loign√© des autres... (le 31). On peut donc regarder d'autres crit√®res (10-B) -->

10-B/ Observations influentes : Pour identifier les observations qui influent le plus dans les estimations (celles dont une faible variation des valeurs induit une modification importante des estimations), plusieurs outils compl√©mentaires existent : les **DFBETAS** (bfb.[nom_de_variable]), les **DFFITS**, les **rapports de covariance** et les **distances de Cook**. Si besoin est, pour identifier les observations influentes, on fait  :

```{r influence, echo = TRUE, eval = FALSE}
summary(influence.measures(reg))
``` 

R√©pondre √† la question initiale. 

<!-- R√©ponse en demi-teinte car avec le seul crit√®re des distances de cook, aucune valeur n'√©tait ab√©rrante. Mais on voit tout de m√™me que l'obersation 31 est "influente" (on dit alors qu'elle peut "driver" le signal, i.e. diriger (ou tirer vers le haut ou la bas) nos coefficients - la pente de la droite de regression) -->
<!-- Il serait bon de regarder plus attentivement si l'observation "31" se distingue "trop" des autres dans les graphiques des donn√©es (type "pairs") et peut etre la retirer de notre mod√©lisation -->

\newpage

## Exercice 2 : Comparaison de 2 mod√®les

A notre jeu de donn√©es `trees`, nous ajoutons 2 nouvelles variables cr√©√©es de toute pi√®ce comme suit : 

```{r exo2, eval = TRUE, echo = TRUE}
mydata <- trees
set.seed(25012021)
mydata$X3 <- rnorm(n = nrow(trees), mean = 30, sd = 1)
set.seed(25012021)
mydata$X4 <- rnorm(n = nrow(trees), mean = 60, sd = 3)
str(mydata)
```

N.B. : la fonction `set.seed()` vous permettra de rendre vos simulations reproductibles. Si vous utilisez des fonctions qui g√©n√©√®ent des nombres al√©atoires (comme `rnorm()` ici), et que vous souhaitez partager les m√™mes donn√©es avec d'autres personnes ou simplement retrouver les m√™mes r√©sultats une prochaine fois, il est important d'utiliser une graine = "seed" √† choisir. 

Pour tester l'influence d'une ou plusieurs variables dans un mod√®le alternatif, tout en prenant en consid√©ration les autres variables, on peut utiliser le **test ANOVA** : Au seuil 5% e.g.  
Si p-valeur > 0.05, alors les variables √©tudi√©es dans le mod√®le alternatif ne contribuent pas significativement √† expliquer notre variable d‚Äôint√©r√™t, comparativement au mod√®le de base".


Ici, on veut tester H0 : $\beta_3 = \beta_4 = 0$ en sachant qu'il y a toujours les variables Girth et Height dans le mod√®le. On effectue :

```{r anova, echo = TRUE, eval = TRUE}
reg1 = lm(Volume ~ Girth + Height + X3 + X4, data = mydata)
reg2 = lm(Volume ~ Girth + Height, data = mydata)
anova(reg1, reg2)
```

Reg1 est le mod√®le alternatif test√©, Reg2 est le mod√®le de base. 
1/ A la lecture de ces r√©sultats, que pouvez-vous conclure ? 

<!-- On lit la p-valeur = 0.8403 -->
<!-- si p-valeur > 0.05, alors les variables √©tudi√©es ne contribuent pas significativement au mod√®le. -->
<!-- ici le meilleur mod√®le est le modele 2 : X3 et X4 ne contribuent pas significativement au mod√®le... (comme attendu!)-->

2/ Crit√®res **AIC** et **BIC**

Ces crit√®res AIC et BIC reposent sur un compromis "biais - parcimonie". Plus petits ils sont, meilleur est le mod√®le.

```{r AICBIC, echo = TRUE, eval=TRUE}
message("reg1")
message("AIC = ", AIC(reg1))
message("BIC = ", BIC(reg1))

message("reg2")
message("AIC = ", AIC(reg2))
message("BIC = ", BIC(reg2))
```

Votre conclusion change-t-elle avec ces nouveaux r√©sultats ? 
<!-- Non, le mod√®le Reg2 a toujours les plus petites valeurs. -->


3/ Question Suppl : Tester la selection de mod√®le

```{r selection1, echo = TRUE, eval=TRUE}
library(stats)
head(swiss)
summary(lm1 <- lm(Fertility ~ ., data = swiss))
slm1 <- step(lm1)
summary(slm1)
slm1$anova
```

```{r selection2, echo = TRUE, eval=TRUE}
library(stats)
set.seed(25012021)
mydata$X5 <- rnorm(n = nrow(trees), mean = 42, sd = 3)
str(mydata)
# Pour utiliser l'approche pas √† pas avec le AIC, puis obtenir les r√©sultats statistiques associ√©s au mod√®le s√©lectionn√© :
reg = lm(Volume ~ Girth + Height + X3 + X4 + X5, data = mydata)
?step
reg_select <- step(reg, direction = "backward", k = 2)
summary(reg_select)
## essayez l'argument keep 
```


\newpage

# GLM : Cas Binomial - R√©gression Logistique

On consid√®re une population P divis√©e en 2 groupes d‚Äôindividus G1 et G2 distinguables par des variables $X_1,..., X_p$. Soit Y la variable qualitative valant 1 si l‚Äôindividu consid√©r√© appartient √† G1 et 0 sinon. On souhaite expliquer Y √† partir de $X_1,..., X_p$.

Dans le cadre d'une r√©gression logistique, on souhaite estimer la probabilit√© qu‚Äôun individu i v√©rifiant $(X_1,..., X_p) = x$ appartienne au groupe G1 :  

$$p(x) = \mathbb{P}(\{Y=1\}|x) = \mathbb{E}(Y|x)$$
$$p(x) = \beta_0 + \beta_1x_1 + ... + \beta_px_p$$
La transformation logit s'applique donc dans ce cas.  


## Exercice 3 : R√©gression logistique simple


Dans cette configuration, nous utiliserons des donn√©es `T2Ddata`, simul√©es comme suit :  

+ `CC` est la variable qualitative binaire qui traduit le statut "cas" (1) pour d√©finir le groupe des individus diab√©tiques et "ctrl", contr√¥le, (0) pour d√©finir les individus non diab√©tiques. 
+ `weight` la variable num√©rique qui repr√©sente le poids des individus.  

```{r T2Ddata, echo = TRUE, eval = TRUE}
T2Ddata <- data.frame(
  weight = c(35.9, 38.3, 55.7, 41.7, 43.2, 49.1, 45, 45.3, 46.1, 46.9, 48.1, 
    48.9, 49.2, 51.2, 56.4, 51.7, 51.8, 52.6, 52.9, 51.3, 53.7, 55, 
    55.4, 55.8, 58, 58.7, 60.3, 61.1, 61.5, 63.1), 
  CC = factor(x = c(rep("0", 15), rep("1", 15)), levels = c("0", "1"), labels = c("CTRL", "CAS")) 
)
str(T2Ddata)
```

1/ Visualiser les donn√©es 

```{r viz, echo = FALSE, eval = TRUE}
plot(T2Ddata$weight, T2Ddata$CC)
```

2/ R√©aliser la r√©gression logistique mod√©lisant `CC` en fonction de `weight`. 

```{r glmlog, eval = FALSE, echo = FALSE}
reg <- glm(formula = CC ~ weight, data = T2Ddata, family = binomial(link = "logit"))
summary(reg)
```

3/ **Rapport des c√¥tes** ou **odds ratio**  

**D√©finition : i $X_j$ augmente d‚Äôune unit√©, alors le rapport des c√¥tes est $RC_j = \mathbb{exp}(\beta_j)$.**    

Par cons√©quent,  

+ si **$RC_j$ > 1**, l‚Äôaugmentation d‚Äôune unit√© de Xj entra√Æne une **augmentation des chances que {Y = 1} se r√©alise**,  
+ si **$RC_j$ = 1**, l‚Äôaugmentation d‚Äôune unit√© de **Xj n‚Äôa pas d‚Äôimpact sur Y**,  
En effet, si $\beta_j = 0$, alors $RC_j = \mathbb{exp}(0) = 1$  
+ si **$RC_j$ < 1**, l‚Äôaugmentation d‚Äôune unit√© de Xj entra√Æne une **augmentation des chances que {Y = 0} se r√©alise**.

=> Calculer l'odd ratio de weight.  

<!-- Dans R, on obtient ces valeurs comme suit :  -->

```{r OR, eval = FALSE, echo = FALSE}
OR = exp(coef(reg)) 
OR>1
```

<!-- L'OR de weight est > 1 donc l‚Äôaugmentation d‚Äôune unit√© de weight entra√Æne une augmentation des chances que {CC = 1} se r√©alise, i.e. l'augmentation du poids augmente le risque de venir diabetique, selon nos donn√©es.  -->

4/ Avec ce nouveau jeu de donn√©es `T2Ddata2`, refaites les m√™mes op√©ration (question 1 √† 3). Que se passe-t-il ?  

```{r T2Ddata2, echo = TRUE, eval = TRUE}
T2Ddata2 <- data.frame(
  weight = sort(c(35.9, 38.3, 55.7, 41.7, 43.2, 49.1, 45, 45.3, 46.1, 46.9, 48.1, 
    48.9, 49.2, 51.2, 56.4, 51.7, 51.8, 52.6, 52.9, 51.3, 53.7, 55, 55.4, 55.8, 58, 58.7, 60.3, 61.1, 61.5, 63.1)), 
  CC = factor(x = c(rep("0", 15), rep("1", 15)), levels = c("0", "1"), labels = c("CTRL", "CAS")) 
)
str(T2Ddata2)
```

<!-- Executer les commandes suivantes  -->

```{r glmlog2, eval = FALSE, echo = FALSE}
plot(T2Ddata2$weight, T2Ddata2$CC)
reg2 <- glm(formula = CC ~ weight, data = T2Ddata2, family = binomial(link = "logit"))
summary(reg2)
OR2 = exp(coef(reg2))
OR2
```

<!-- Le graphique nous montre une tr√®s nette partition entre les mesures (on pourrait tracer un trait net vertical) -->
<!-- A la r√©alisation du GLM : Le warning suivant s'affiche :  -->
<!-- Warning messages: -->
<!-- 1: glm.fit: l'algorithme n'a pas converg√©  -->
<!-- 2: glm.fit: des probabilit√©s ont √©t√© ajust√©es num√©riquement √† 0 ou 1  -->
<!-- Vu les donn√©es (construites expr√®s) ce warning √©tait attendu. Mais il peut arriver aussi sur des donn√©es r√©elles, il faudra alors en garder la trace et ne pas seulement retourner les estimations -->
<!-- L'OR de weight "explose"  (evidement puisqu'il n'a pas de sens, au vu du warning) -->

<!-- Ici la mod√©lisation n'√©tait pas pertinente car la partition entre les 2 groupes √©tait totale selon la mesure utilis√©e dans le mod√®le. On s'en rend un peu mieux compte avec le boxplot suivant : `boxplot(T2Ddata2$weight~T2Ddata2$CC)` -->


\newpage

## Exercice 4 : R√©gression logistique multiple

Nous allons utiliser le jeu de donn√©es `esoph`, disponible dans le package `datasets` (nativement charg√© dans R).  

Soit $j \in \{0,..., p\}$. Le **test de la d√©viance** vise √† √©valuer l‚Äôinfluence (ou la contribution) de Xj sur Y. La p-valeur associ√©e utilise la loi du Chi-deux : si \*, l‚Äôinfluence de Xj sur Y est significative, si \*\*, elle est tr√®s significative et si \*\*\*, elle est hautement significative.  

Ici, on souhaite mod√©liser la proportion d'individus cas/control d√©finit dans les 2 colonnes ncases et ncontrols.  

Evaluer les 2 mod√®les suivants et noter les diff√©rences. 

```{r esoph, echo = TRUE, eval = FALSE}
str(esoph)

model1 <- glm(
  cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp,
  data = esoph, family = binomial(link = "logit")
)
summary(model1)
anova(model1, test = "Chisq")

model2 <- glm(
  cbind(ncases, ncontrols) ~ agegp + unclass(tobgp) + unclass(alcgp),
  data = esoph, family = binomial()
)
summary(model2)
anova(model2, test = "Chisq")
```

<!-- Modele 1 effets avec interaction de alcohol et tobacco (tobgp * alcgp) + groupe d'age  -->
<!-- Modele 2 test un effet lin√©aire de alcohol et tobacco (avec unclass()) et sans interaction. -->
<!-- Ceci est fait pour vous montrer qu'on peut parfois se demander si une interaction est necessaire... on pourra ici le tester. et aussi pour vous montrer que la classe des variables est importante et joue un role dans leur consid√©ration dans le mod√®le (dans les estimations de vos coefs) -->

\newpage

# Pour aller plus loin

## Comple√©ent

Les √©l√©ments ci-dessous ne seront pas forcement test√©s en TP (ni vu en cours).  
Mais vous pourrez commencer √† vous familiariser avec ces concepts gr√¢ces √† ces quelques remarques.  
De plus si vous voulez aller plus loin, je vous recommande de r√©aliser les √©tudes propos√© ici :  

https://chesneau.users.lmno.cnrs.fr/etudes-reg.pdf

Le cours allant avec est aussi disponible ici :  

https://chesneau.users.lmno.cnrs.fr/Reg-M2.pdf

## Multicolin√©arit√©

la variance de $\hat{\beta}_j$ explose et entra√©ne une grande instabilit√© dans l'estimation de $\beta_j$ et fausse tous les tests statistiques.  

En particulier, si au moins une variable parmi $X_1, ..., X_p$ a une liaison lin√©aire avec d'autres, il est possible qu'aucune variable ne montre d'influence significative sur Y et cela, en d√©pit de toute logique, et du test de Fisher qui peut quand m√™me indiquer une influence significative globale des coefficients (car il prend en compte toutes les variables).  

### R√©√®le de Klein

Si une ou plusieurs valeurs au carr√© sont proches de R2, alors on soup√ßonne que les variables associ√©es sont colin√©aires. 

```{r, klein, echo = TRUE, eval = FALSE}
c = cor(cbind(X1, X2, X3), cbind(X1, X2, X3))
c^2
``` 

### VIF

On appelle **vif** $V_j$ le facteur d'inflation de la variance associ√© √† la variable $X_j$. Si $V_j \ge 5$, alors on admet que $X_j$ a un lien lin√©aire avec les autres variables. 

```{r, vif, echo = TRUE, eval = FALSE}
library(car)
vif(reg)
``` 

## S√©lection de variables

Il est int√©ressant de d√©terminer la meilleure combinaison des variables X1, ..., Xp qui explique Y.  r l‚Äôapproche qui consiste √† √©liminer d‚Äôun seul coup les variables non significatives n‚Äôest pas bonne ;  ertaines variables peuvent √™tre corr√©l√©es √† d‚Äôautres, ce qui peut masquer leur r√©elle influence sur Y.

Plusieurs approches sont possibles :

+ Approche exhaustive,
+ Approche en arri√®re,
+ Approche en avant,
+ Approche pas √† pas. 

Rappel sur les crit√®res Cp, AIC et BIC :  
Ces crit√®res Cp de Mallows, AIC et BIC reposent sur un compromis "biais - parcimonie". Plus petits ils sont, meilleur est le mod√®le.

```{r selection, echo = TRUE, eval = FALSE}
AIC(reg)
BIC(reg)

library(leaps)
v = regsubsets(Y ~ X1 + X2 + X3, w, method = "backward")
plot(v, scale = "bic")
# Notons que l'option scale = "aic" n'existe pas. On obtiendrait toutefois la m√©me s√©lection
# de variables que celle obtenue avec l'option scale = "bic"

library(stats)
# Pour utiliser l'approche pas √† pas avec le AIC, puis obtenir les r√©sultats statistiques associ√©s au mod√®le s√©lectionn√© :
reg2 = step(reg, direction = "both", k = 2)
summary(reg2)
# Pour consid√©rer le BIC, on prend k = log(length(Y))
``` 
